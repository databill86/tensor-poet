{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Poet\n",
    "A tensorflow deep LSTM model for text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content\n",
    "This notebook contains six sections:\n",
    "1. TextLibrary: utilities to work with text files\n",
    "  * loading of a list of files\n",
    "  * encoding for training\n",
    "  * formatted output with quote-highlighting\n",
    "2. Definition of the tensorflow model\n",
    "3. Model and training parameters\n",
    "4. The actual training on the data (required 1. - 3.)\n",
    "  * Training can be restarted, since the model is saved periodically.\n",
    "5. Generation of text from the trained model (requires 1. - 4.)\n",
    "6. In dialog with with the model (requires 1. - 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. TextLibrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TextLibrary class: text library for training, encoding, batch generation,\n",
    "# and formatted source display\n",
    "class TextLibrary:\n",
    "    def __init__(self, filenames, max=100000000):\n",
    "        self.filenames = filenames\n",
    "        self.data=''\n",
    "        self.files=[]\n",
    "        index = 1\n",
    "        for filename in filenames:\n",
    "            fd={}\n",
    "            fd[\"name\"] = os.path.splitext(os.path.basename(filename))[0]\n",
    "            self.c2i = {}\n",
    "            self.i2c = {}\n",
    "            try:\n",
    "                f = open(filename)\n",
    "                dat = f.read(max)\n",
    "                self.data += dat\n",
    "                fd[\"data\"] = dat\n",
    "                fd[\"index\"] = index\n",
    "                index += 1\n",
    "                self.files.append(fd)\n",
    "                f.close()\n",
    "            except OSError:\n",
    "                print(\"  ERROR: Cannot read: \", filename)\n",
    "        ind = 0\n",
    "        for c in self.data: # sets are not deterministic\n",
    "            if c not in self.c2i:\n",
    "                self.c2i[c] = ind\n",
    "                self.i2c[ind] = c\n",
    "                ind += 1\n",
    "        self.ptr = 0\n",
    "            \n",
    "    def printColoredIPython(self, textlist, pre='', post=''):\n",
    "        bgcolors = ['#d4e6f1', '#d8daef', '#ebdef0', '#eadbd8', '#e2d7d5', '#edebd0',\n",
    "                    '#ecf3cf', '#d4efdf', '#d0ece7', '#d6eaf8', '#d4e6f1', '#d6dbdf',\n",
    "                    '#f6ddcc', '#fae5d3', '#fdebd0', '#e5e8e8', '#eaeded', '#A9CCE3']\n",
    "        out = ''\n",
    "        for txt, ind in textlist:\n",
    "            txt = txt.replace('\\n','<br>')\n",
    "            if ind==0:\n",
    "                out += txt\n",
    "            else:\n",
    "                out += \"<span style=\\\"background-color:\"+bgcolors[ind%16]+\";\\\">\" + txt +\\\n",
    "                       \"</span>\"+\"<sup>[\" + str(ind) + \"]</sup>\"\n",
    "        display(HTML(pre+out+post))\n",
    "        \n",
    "    def sourceHighlight(self, txt, minQuoteSize=10):\n",
    "        tx = txt\n",
    "        out = []\n",
    "        qts = []\n",
    "        txsrc=[(\"Sources: \", 0)]\n",
    "        sc=False\n",
    "        noquote = ''\n",
    "        while len(tx)>0:  # search all library files for quote 'txt'\n",
    "            mxQ = 0\n",
    "            mxI = 0\n",
    "            mxN = ''\n",
    "            found = False\n",
    "            for f in self.files:  # find longest quote in all texts\n",
    "                p = minQuoteSize\n",
    "                if p<=len(tx) and tx[:p] in f[\"data\"]:\n",
    "                    p = minQuoteSize + 1\n",
    "                    while p<=len(tx) and tx[:p] in f[\"data\"]:\n",
    "                        p += 1\n",
    "                    if p-1>mxQ:\n",
    "                        mxQ = p-1\n",
    "                        mxI = f[\"index\"]\n",
    "                        mxN = f[\"name\"]\n",
    "                        found = True\n",
    "            if found:  # save longest quote for colorizing\n",
    "                if len(noquote)>0:\n",
    "                    out.append((noquote, 0))\n",
    "                    noquote = ''\n",
    "                out.append((tx[:mxQ],mxI))\n",
    "                tx = tx[mxQ:]\n",
    "                if mxI not in qts:  # create a new reference, if first occurence\n",
    "                    qts.append(mxI)\n",
    "                    if sc:\n",
    "                        txsrc.append((\", \", 0))\n",
    "                    sc = True\n",
    "                    txsrc.append((mxN,mxI))\n",
    "            else:\n",
    "                noquote += tx[0]\n",
    "                tx = tx[1:]\n",
    "        if len(noquote)>0:\n",
    "            out.append((noquote, 0))\n",
    "            noquote = ''\n",
    "        self.printColoredIPython(out)\n",
    "        if len(qts)>0:  # print references, if there is at least one source\n",
    "            self.printColoredIPython(txsrc, pre=\"<small><p style=\\\"text-align:right;\\\">\",\n",
    "                                     post=\"</p></small>\")\n",
    "    \n",
    "    def getSlice(self, length):\n",
    "        if (self.ptr + length >= len(self.data)):\n",
    "            self.ptr = 0\n",
    "        if self.ptr == 0:\n",
    "            rst = True\n",
    "        else:\n",
    "            rst = False\n",
    "        sl = self.data[self.ptr:self.ptr+length]\n",
    "        self.ptr += length\n",
    "        return sl, rst\n",
    "    \n",
    "    def decode(self, ar):\n",
    "         return ''.join([self.i2c[ic] for ic in ar])\n",
    "            \n",
    "    def getRandomSlice(self, length):\n",
    "        p = random.randrange(0,len(self.data)-length)\n",
    "        sl = self.data[p:p+length]\n",
    "        return sl\n",
    "    \n",
    "    def getSliceArray(self, length):\n",
    "        ar = np.array([c for c in self.getSlice(length)[0]])\n",
    "        return ar\n",
    "        \n",
    "    def getSample(self, length):\n",
    "        s, rst = self.getSlice(length+1)\n",
    "        X = [self.c2i[c] for c in s[:-1]]\n",
    "        y = [self.c2i[c] for c in s[1:]]\n",
    "        return (X, y, rst)\n",
    "    \n",
    "    def getRandomSample(self, length):\n",
    "        s = self.getRandomSlice(length+1)\n",
    "        X = [self.c2i[c] for c in s[:-1]]\n",
    "        y = [self.c2i[c] for c in s[1:]]\n",
    "        return (X, y)\n",
    "    \n",
    "    def getSampleBatch(self, batch_size, length):\n",
    "        smpX = []\n",
    "        smpy = []\n",
    "        for i in range(batch_size):\n",
    "            Xi, yi, rst = self.getSample(length)\n",
    "            smpX.append(Xi)\n",
    "            smpy.append(yi)\n",
    "        return smpX, smpy, rst\n",
    "        \n",
    "    def getRandomSampleBatch(self, batch_size, length):\n",
    "        smpX = []\n",
    "        smpy = []\n",
    "        for i in range(batch_size):\n",
    "            Xi, yi = self.getRandomSample(length)\n",
    "            smpX.append(Xi)\n",
    "            smpy.append(yi)\n",
    "        return smpX, smpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defintion of the Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The tensorflow model for text generation\n",
    "class TensorPoetModel:\n",
    "    def __init__(self, params):\n",
    "        self.vocab_size = params[\"vocab_size\"]\n",
    "        self.neurons = params[\"neurons\"]\n",
    "        self.layers = params[\"layers\"]\n",
    "        self.learning_rate = params[\"learning_rate\"]\n",
    "        self.steps = params[\"steps\"]\n",
    "        # self.clip = -1.0 * params[\"clip\"]\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        # Training & Generating:\n",
    "        self.X = tf.placeholder(tf.int32, shape=[None, self.steps])\n",
    "        self.y = tf.placeholder(tf.int32, shape=[None, self.steps])\n",
    "\n",
    "        onehot_X = tf.one_hot(self.X, self.vocab_size)\n",
    "        onehot_y = tf.one_hot(self.y, self.vocab_size)\n",
    "\n",
    "        basic_cell = tf.contrib.rnn.BasicLSTMCell(self.neurons)\n",
    "        stacked_cell = tf.contrib.rnn.MultiRNNCell([basic_cell] * self.layers)\n",
    "\n",
    "        self.batch_size = tf.placeholder(tf.int32)\n",
    "        self.init_state_0 = stacked_cell.zero_state(self.batch_size, tf.float32)\n",
    "\n",
    "        self.init_state = self.init_state_0\n",
    "\n",
    "        with tf.variable_scope('rnn') as scope:\n",
    "            rnn_outputs, states = tf.nn.dynamic_rnn(stacked_cell, onehot_X, \n",
    "                                                    initial_state=self.init_state, \n",
    "                                                    dtype=tf.float32)\n",
    "            self.init_state = states\n",
    "\n",
    "        self.final_state = self.init_state\n",
    "        stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, self.neurons])\n",
    "\n",
    "        softmax_w = tf.Variable(tf.random_normal([self.neurons, self.vocab_size]), dtype=tf.float32)\n",
    "        softmax_b = tf.Variable([self.vocab_size], dtype=tf.float32)\n",
    "            \n",
    "        logits_raw = tf.matmul(stacked_rnn_outputs, softmax_w) + softmax_b\n",
    "        logits = tf.reshape(logits_raw, [-1, self.steps, self.vocab_size])\n",
    "\n",
    "        output_softmax = tf.nn.softmax(logits)\n",
    "\n",
    "        self.temperature = tf.placeholder(tf.float32)\n",
    "        self.output_softmax_temp = tf.nn.softmax(tf.div(logits, self.temperature))\n",
    "\n",
    "        softmax_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=onehot_y, logits=logits)\n",
    "\n",
    "        self.cross_entropy = tf.reduce_mean(softmax_entropy)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "\n",
    "        self.training_op = optimizer.minimize(self.cross_entropy)\n",
    "        \n",
    "        # Clipping isn't necessary, even for really deep networks:\n",
    "        # grads = optimizer.compute_gradients(self.cross_entropy)\n",
    "        # minclip = -1.0 * self.clip\n",
    "        # capped_grads = [(tf.clip_by_value(grad, minclip, self.clip), var) for grad, var in grads]\n",
    "        # self.training_op = optimizer.apply_gradients(capped_grads)\n",
    "\n",
    "        self.prediction = tf.cast(tf.argmax(output_softmax, -1), tf.int32)\n",
    "        correct_prediction = tf.equal(self.y, self.prediction)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        error = 1.0 - self.accuracy\n",
    "\n",
    "        \n",
    "        # Tensorboard\n",
    "        tf.summary.scalar(\"cross-entropy\", self.cross_entropy)\n",
    "        tf.summary.scalar(\"error\", error)\n",
    "        self.summary_merged = tf.summary.merge_all()\n",
    "\n",
    "        # Init\n",
    "        self.init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parameters for model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "libdesc = {\n",
    "    \"name\": \"TinyShakespeare\",\n",
    "    \"description\": \"Small Shakespeare 'standard' corpus\",\n",
    "    \"lib\": [\n",
    "        'data/tiny-shakespeare.txt',\n",
    "    ]\n",
    "}\n",
    "\n",
    "textlib = TextLibrary(libdesc[\"lib\"])\n",
    "\n",
    "# Model parameter:\n",
    "modelParams = {\n",
    "    \"vocab_size\": len(textlib.i2c),\n",
    "    \"neurons\": 256,\n",
    "    \"layers\": 2,\n",
    "    \"learning_rate\": 1.e-3,\n",
    "    \"steps\": 128,\n",
    "}\n",
    "\n",
    "# Look for optional json description of a library:\n",
    "if os.path.exists('bk/lib-phil-deen.json'):\n",
    "    with open('bk/lib-phil-deen.json') as data_file:    \n",
    "        libdescphil = json.load(data_file)\n",
    "        textlib = TextLibrary(libdescphil[\"lib\"])\n",
    "        modelParams[\"layers\"] = 8\n",
    "\n",
    "model = TensorPoetModel(modelParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training Parameter:\n",
    "\n",
    "trainParams = {\n",
    "    \"model_name\": \"philosopher\",\n",
    "    \"checkpoint\": \"model.ckpt\",\n",
    "    \"logdir\": \"tensorlog\",\n",
    "    \"max_iter\": 1000000,\n",
    "    \"batch_size\": 128,\n",
    "    \"restoreCheckpoints\": True,\n",
    "    \"generateDuringTraining\": False,\n",
    "    \"generated_text_size\": 500,\n",
    "    \"verbose\": False,\n",
    "    \"statusEveryNIter\": 200,\n",
    "    \"saveEveryNIter\": 500,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorboard: 'tensorboard --logdir /home/dsc/git/AI/tensor-poet/tensorlog'\n",
      "Restoring checkpoint at 190500: /home/dsc/git/AI/tensor-poet/tensorlog/model.ckpt-190500\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Assign requires shapes of both tensors to match. lhs shape= [321,1024] rhs shape= [625,1024]\n\t [[Node: save/Assign_13 = Assign[T=DT_FLOAT, _class=[\"loc:@rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights/Adam_1, save/RestoreV2_13/_69)]]\n\nCaused by op 'save/Assign_13', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-d85189e38e31>\", line 17, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1051, in __init__\n    self.build()\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1081, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 675, in build\n    restore_sequentially, reshape)\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 414, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 47, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [321,1024] rhs shape= [625,1024]\n\t [[Node: save/Assign_13 = Assign[T=DT_FLOAT, _class=[\"loc:@rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights/Adam_1, save/RestoreV2_13/_69)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [321,1024] rhs shape= [625,1024]\n\t [[Node: save/Assign_13 = Assign[T=DT_FLOAT, _class=[\"loc:@rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights/Adam_1, save/RestoreV2_13/_69)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d85189e38e31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mstart_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlastSave\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring checkpoint at {}: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlastSave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlastSave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_iter\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1437\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1439\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [321,1024] rhs shape= [625,1024]\n\t [[Node: save/Assign_13 = Assign[T=DT_FLOAT, _class=[\"loc:@rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights/Adam_1, save/RestoreV2_13/_69)]]\n\nCaused by op 'save/Assign_13', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-d85189e38e31>\", line 17, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1051, in __init__\n    self.build()\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1081, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 675, in build\n    restore_sequentially, reshape)\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 414, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 47, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [321,1024] rhs shape= [625,1024]\n\t [[Node: save/Assign_13 = Assign[T=DT_FLOAT, _class=[\"loc:@rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights/Adam_1, save/RestoreV2_13/_69)]]\n"
     ]
    }
   ],
   "source": [
    "# Run training:\n",
    "with tf.Session() as sess:\n",
    "    batch_size = trainParams[\"batch_size\"]\n",
    "    epl = len(textlib.data) / (batch_size * model.steps)\n",
    "    model.init.run()\n",
    "\n",
    "    tflogdir = trainParams[\"logdir\"]\n",
    "    tflogdir = os.path.realpath(tflogdir)\n",
    "    if not os.path.exists(tflogdir):\n",
    "        os.makedirs(tflogdir)\n",
    "    print(\"Tensorboard: 'tensorboard --logdir {}'\".format(tflogdir))\n",
    "\n",
    "    train_writer = tf.summary.FileWriter(tflogdir, sess.graph)\n",
    "    train_writer.add_graph(sess.graph)\n",
    "    \n",
    "    # Used for saving the training parameters periodically\n",
    "    saver = tf.train.Saver()\n",
    "    checkpoint_file = os.path.join(tflogdir, trainParams[\"checkpoint\"])\n",
    "    # FFR: tf.train.export_meta_graph(filename=None, meta_info_def=None, graph_def=None, saver_def=None, collection_list=None, as_text=False, graph=None, export_scope=None, clear_devices=False, **kwargs)\n",
    "    start_iter = 0\n",
    "    if trainParams[\"restoreCheckpoints\"]:\n",
    "        lastSave = tf.train.latest_checkpoint(tflogdir, \n",
    "                                              latest_filename=None)\n",
    "        if lastSave is not None:\n",
    "            pt = lastSave.rfind('-')\n",
    "            if pt != -1:\n",
    "                pt += 1\n",
    "                start_iter=int(lastSave[pt:])\n",
    "            print(\"Restoring checkpoint at {}: {}\".format(start_iter, lastSave))\n",
    "            saver.restore(sess, lastSave)\n",
    "    \n",
    "    for iteration in range(start_iter, trainParams[\"max_iter\"]):\n",
    "        # Train with batches from the text library:\n",
    "        X_batch, y_batch = textlib.getRandomSampleBatch(batch_size, model.steps)\n",
    "        i_state = sess.run([model.init_state_0], feed_dict={model.batch_size: batch_size})\n",
    "        i_state, _ = sess.run([model.final_state, model.training_op],\n",
    "                              feed_dict={model.X: X_batch, model.y: y_batch,\n",
    "                                         model.batch_size: batch_size, model.init_state: i_state})\n",
    "\n",
    "        # Output training statistics every 100 iterations:\n",
    "        if iteration % 200 == 0:\n",
    "            ce, accuracy, prediction, summary = sess.run([model.cross_entropy,\n",
    "                                                          model.accuracy, model.prediction,\n",
    "                                                          model.summary_merged],\n",
    "                                             feed_dict={model.X: X_batch, model.y: y_batch,\n",
    "                                                        model.batch_size: batch_size})\n",
    "            train_writer.add_summary(summary, iteration)\n",
    "            ep = iteration / epl\n",
    "            print(\"Epoch: {0:.2f}, iter: {1:d}, cross-entropy: {2:.3f}, accuracy: {3:.5f}\".format(ep, iteration, ce, accuracy))\n",
    "            if verbose:\n",
    "                for ind in range(1): # model.batch_size):\n",
    "                    ys = textlib.decode(y_batch[ind]).replace('\\n', ' | ')\n",
    "                    yps = textlib.decode(prediction[ind]).replace('\\n', ' | ')\n",
    "                    print(\"   y:\", ys)\n",
    "                    print(\"  yp:\", yps)\n",
    "\n",
    "        # Generate sample texts for different temperature every ..NIter iterations:\n",
    "        if (iteration+1) % trainParams[\"statusEveryNIter\"] == 0:\n",
    "            \n",
    "            # Save training data\n",
    "            saver.save(sess, checkpoint_file, global_step=iteration+1)\n",
    "\n",
    "            if generateDuringTraining:\n",
    "                # Generate sample\n",
    "                for t in range(2, 11, 4):\n",
    "                    temp = float(t) / 10.0;\n",
    "                    g_state = sess.run([model.init_state_0], feed_dict={model.batch_size: 1})\n",
    "                    xs = ' ' * model.steps\n",
    "                    xso = ''\n",
    "                    for i in range(generated_text_size):\n",
    "                        X_new = np.transpose([[textlib.c2i[sj]] for sj in xs])\n",
    "                        g_state, y_pred = sess.run([model.final_state, model.output_softmax_temp], \n",
    "                                                  feed_dict={model.X: X_new, model.init_state: g_state,\n",
    "                                                             model.batch_size: 1, model.temperature: temp})\n",
    "                        inds=list(range(model.vocab_size))\n",
    "                        ind = np.random.choice(inds, p=y_pred[0, -1].ravel())\n",
    "                        nc = textlib.i2c[ind]\n",
    "                        xso += nc\n",
    "                        xs = xs[1:]+nc\n",
    "\n",
    "                    print(\"----------------- temperature =\", temp, \"----------------------\")\n",
    "                    # print(xso)\n",
    "                    textlib.sourceHighlight(xso, 20)   # 20: minimum quote size detected.\n",
    "                print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generation of text from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating text using the model data generated during training.\n",
    "def ghostWriter(textsize, temperature=1.0):\n",
    "    xso = None\n",
    "    with tf.Session() as sess:\n",
    "        model.init.run()\n",
    "\n",
    "        tflogdir = os.path.realpath(trainParams[\"logdir\"])\n",
    "        if not os.path.exists(tflogdir):\n",
    "            print(\"You haven't trained a model, no data found at: {}\".format(tflogdir))\n",
    "            return None\n",
    "\n",
    "        # Used for saving the training parameters periodically\n",
    "        saver = tf.train.Saver()\n",
    "        checkpoint_file = os.path.join(tflogdir, trainParams[\"checkpoint\"])\n",
    "\n",
    "        lastSave = tf.train.latest_checkpoint(tflogdir, latest_filename=None)\n",
    "        if lastSave is not None:\n",
    "            pt = lastSave.rfind('-')\n",
    "            if pt != -1:\n",
    "                pt += 1\n",
    "                start_iter=int(lastSave[pt:])\n",
    "            print(\"Restoring checkpoint at {}: {}\".format(start_iter, lastSave))\n",
    "            saver.restore(sess, lastSave)\n",
    "        else:\n",
    "            print(\"No checkpoints have been saved at:{}\".format(trainParams[\"logdir\"]))\n",
    "            return None\n",
    "\n",
    "        g_state = sess.run([model.init_state_0], feed_dict={model.batch_size: 1})\n",
    "        xs = ' ' * model.steps\n",
    "        xso = ''\n",
    "        for i in range(textsize):\n",
    "            X_new = np.transpose([[textlib.c2i[sj]] for sj in xs])\n",
    "            g_state, y_pred = sess.run([model.final_state, model.output_softmax_temp], \n",
    "                                      feed_dict={model.X: X_new, model.init_state: g_state,\n",
    "                                                 model.batch_size: 1, model.temperature: temperature})\n",
    "            inds=list(range(model.vocab_size))\n",
    "            ind = np.random.choice(inds, p=y_pred[0, -1].ravel())\n",
    "            nc = textlib.i2c[ind]\n",
    "            xso += nc\n",
    "            xs = xs[1:]+nc\n",
    "    return(xso)\n",
    "\n",
    "\n",
    "def detectPlagiarism(generatedtext, textlibrary, minQuoteLength=10):\n",
    "    textlibrary.sourceHighlight(generatedtext, minQuoteLength)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tgen=ghostWriter(10000)\n",
    "detectPlagiarism(tgen, textlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. A dialog with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do a dialog with the recursive neural net trained above:\n",
    "# def genDialogAnswer(prompt, g_state=None, endPrompt='.', maxEndPrompts=2, maxAnswerSize=512, temperature=1.0):\n",
    "def doDialog():\n",
    "    temperature = 0.6  # 0.1 (frozen character) - 1.3 (creative/chaotic character)\n",
    "    endPrompt = '.'  # the endPrompt character is the end-mark in answers.\n",
    "    maxEndPrompts = 4  # look for number of maxEndPrompts until answer is finished.\n",
    "    maxAnswerSize = 2048  # Maximum length of the answer\n",
    "    minAnswerSize = 64  # Minimum length of the answer\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        print(\"Please enter some dialog.\")\n",
    "        print(\"The net will answer according to your input.\")\n",
    "        print(\"'bye' for end,\")\n",
    "        print(\"'reset' to reset the conversation context,\")\n",
    "        print(\"'temperature=<float>' [0.1(frozen)-1.0(creative)]\")\n",
    "        print(\"    to change character of the dialog.\")\n",
    "        print(\"    Current temperature={}.\".format(temperature))\n",
    "        print()\n",
    "        xso = None\n",
    "        bye = False\n",
    "        model.init.run()\n",
    "\n",
    "        tflogdir = os.path.realpath(trainParams[\"logdir\"])\n",
    "        if not os.path.exists(tflogdir):\n",
    "            print(\"You haven't trained a model, no data found at: {}\".format(trainParams[\"logdir\"]))\n",
    "            return \n",
    "\n",
    "        # Used for saving the training parameters periodically\n",
    "        saver = tf.train.Saver()\n",
    "        checkpoint_file = os.path.join(tflogdir, 'model.ckpt')\n",
    "\n",
    "        lastSave = tf.train.latest_checkpoint(tflogdir, latest_filename=None)\n",
    "        if lastSave is not None:\n",
    "            pt = lastSave.rfind('-')\n",
    "            if pt != -1:\n",
    "                pt += 1\n",
    "                start_iter=int(lastSave[pt:])\n",
    "            # print(\"Restoring checkpoint at {}: {}\".format(start_iter, lastSave))\n",
    "            saver.restore(sess, lastSave)\n",
    "        else:\n",
    "            print(\"No checkpoints have been saved at:{}\".format(tflogdir))\n",
    "            return\n",
    "\n",
    "        g_state = sess.run([model.init_state_0], feed_dict={model.batch_size: 1})\n",
    "\n",
    "        bye = False\n",
    "        while not bye:\n",
    "            print(\"> \", end=\"\")\n",
    "            prompt = input()\n",
    "            if prompt == 'bye':\n",
    "                bye = True\n",
    "                print(\"Good bye!\")\n",
    "                continue\n",
    "            if prompt == 'reset':\n",
    "                g_state = sess.run([model.init_state_0], feed_dict={model.batch_size: 1})\n",
    "                print(\"(conversation context reset)\")\n",
    "                continue\n",
    "            if prompt[:len(\"temperature=\")] == \"temperature=\":\n",
    "                t = float(prompt[len(\"temperature=\"):])\n",
    "                if t>0.05 and t<1.4:\n",
    "                    temperature = t\n",
    "                    print(\"(generator temperature now {})\".format(t))\n",
    "                    print()\n",
    "                    continue\n",
    "                print(\"Invalid temperature-value ignored! [0.1-1.0]\")\n",
    "                continue\n",
    "            xs = ' ' * model.steps\n",
    "            xso = ''\n",
    "            for rep in range(1):\n",
    "                for i in range(len(prompt)):\n",
    "                    xs = xs[1:]+prompt[i]\n",
    "                    X_new = np.transpose([[textlib.c2i[sj]] for sj in xs])\n",
    "                    g_state, y_pred = sess.run([model.final_state, model.output_softmax_temp], \n",
    "                                              feed_dict={model.X: X_new, model.init_state: g_state,\n",
    "                                                         model.batch_size: 1, model.temperature: temperature})\n",
    "            ans=0\n",
    "            numEndPrompts = 0\n",
    "            while (ans<maxAnswerSize and numEndPrompts < maxEndPrompts) or ans<minAnswerSize:\n",
    "\n",
    "                X_new = np.transpose([[textlib.c2i[sj]] for sj in xs])\n",
    "                g_state, y_pred = sess.run([model.final_state, model.output_softmax_temp], \n",
    "                                          feed_dict={model.X: X_new, model.init_state: g_state,\n",
    "                                                     model.batch_size: 1, model.temperature: temperature})\n",
    "                inds=list(range(model.vocab_size))\n",
    "                ind = np.random.choice(inds, p=y_pred[0, -1].ravel())\n",
    "                nc = textlib.i2c[ind]\n",
    "                if nc == endPrompt:\n",
    "                    numEndPrompts += 1\n",
    "                xso += nc\n",
    "                xs = xs[1:]+nc\n",
    "                ans += 1\n",
    "            print(xso.replace(\"\\\\n\",\"\\n\"))\n",
    "            textlib.sourceHighlight(xso, 13)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Talk to the net!\n",
    "doDialog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
